{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for 3D keypoint generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from matplotlib import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "rc('animation', html='html5')\n",
    "rcParams['animation.embed_limit'] = 2**128\n",
    "import mdn\n",
    "\n",
    "# Hacky. Is there a better way to load local modules?\n",
    "\n",
    "#%run ../renderer/common.py\n",
    "\n",
    "# still hacky but less hacky\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,os.path.join(parentdir, 'renderer')) \n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import keypoint sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "basedir = '../data/train/'\n",
    "for video_folder in os.listdir(basedir):\n",
    "    for folder in os.listdir(basedir + video_folder):\n",
    "        keypoints = np.load(basedir + video_folder + \"/\" + folder + \"/\" + 'pose3d.npz', allow_pickle=True)\n",
    "        keypoints = keypoints['arr_0']\n",
    "        data.append(keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data\n",
    "\n",
    "**Note:** In order to render a video based on the pose3D data, please run `python renderer/render_pose3d_matplot.py ../data/train/seq_001/pose3d.npz --frames 300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = init_plot()\n",
    "plot_pose(ax, data[9][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = init_plot()\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    plot_pose(ax, data[0][i])\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=range(0,len(keypoints), 20), interval=200)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, look_back = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for dataset in data:\n",
    "        # reshape input to be [samples, features = (keypoints*3dim)] \n",
    "        dataset = np.reshape(dataset,  (dataset.shape[0], dataset.shape[1]*dataset.shape[2]))\n",
    "        for i in range(len(dataset) - look_back-1):\n",
    "            # dataX has dimension [samples, lookback, features = (keypoints*3dim)] \n",
    "            a = dataset[i:(i + look_back), :]     \n",
    "            dataX.append(a)\n",
    "            # dataY has dimension [samples, features = (keypoints*3dim)] \n",
    "            dataY.append(dataset[i + look_back, :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "look_back = 10\n",
    "X, y = create_dataset(data,look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, shuffle= True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(32, input_shape=(look_back, 51),  return_sequences=True))\n",
    "model.add(layers.LSTM(32, return_sequences=True))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(mdn.MDN(51, 3))\n",
    "model.compile(loss=mdn.get_mixture_loss_func(51,3), optimizer=keras.optimizers.Adam())\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "limit = int(np.floor(len(X_train)/BATCH_SIZE))*BATCH_SIZE\n",
    "EPOCHS = 500\n",
    "VAL_SPLIT = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# Define callbacks\n",
    "filepath=\"models/lstm_mdn-E{epoch:02d}-VL{val_loss:.2f}.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "callbacks = [keras.callbacks.TerminateOnNaN(), checkpoint, early_stopping]\n",
    "\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, validation_split=VAL_SPLIT)\n",
    "\n",
    "# Save the Model\n",
    "model.save('models/lstm-mdn.h5')  # creates a HDF5 file of the model\n",
    "\n",
    "# Plot the loss\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(x_test)\n",
    "y_samples = np.apply_along_axis(sample_from_output, 1, y_test, OUTPUT_DIMS, N_MIXES, temp=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "\n",
    "def show_animation(dataset):\n",
    "    fig, ax = init_plot()\n",
    "    trainPredict_reshaped = np.reshape(dataset,(np.shape(dataset)[0],17,3))\n",
    "    def animate(i):\n",
    "        ax.clear()\n",
    "        plot_pose(ax, trainPredict_reshaped[i])\n",
    "\n",
    "    anim = FuncAnimation(fig, animate, frames=range(0,len(dataset),3), interval=200)\n",
    "    plt.close()\n",
    "    return HTML(anim.to_jshtml());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_pose(ax, frame):\n",
    "    ax.clear()\n",
    "    ax.set_xlim3d(-1, 1)\n",
    "    ax.set_ylim3d(-1, 1)\n",
    "    ax.set_zlim3d(0, 2)\n",
    "\n",
    "    for i,kp in enumerate(frame):\n",
    "        ax.scatter(kp[0], kp[1], kp[2], color=cm.plasma(i/17))\n",
    "\n",
    "    for (j_from, j_to) in bones:\n",
    "        ax.plot3D(\n",
    "            [frame[j_from][0], frame[j_to][0]],\n",
    "            [frame[j_from][1], frame[j_to][1]],\n",
    "            [frame[j_from][2], frame[j_to][2]],\n",
    "            'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_performance(model, initial_positions, steps_limit=100, n_mixtures=3, temp=1.0, sigma_temp=0.0, look_back=10):\n",
    "    \"\"\"Generates aperformance\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    performance = [pose for pose in initial_positions]\n",
    "    while (steps < steps_limit):\n",
    "        params = model.predict(np.expand_dims(np.array(performance[-10:]), axis=0))\n",
    "        new_pose = mdn.sample_from_output(params[0], 51, n_mixtures, temp=temp, sigma_temp=sigma_temp)\n",
    "        performance.append(new_pose[0])\n",
    "        steps += 1\n",
    "    return np.array(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = range(0,len(X_test), int(len(X_test)/10))\n",
    "\n",
    "test_performances = [generate_performance(model,X_test[seed], steps_limit=100) for seed in seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_performance = generate_performance(model,X_test[1500], steps_limit=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(longer_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(test_performances[9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
